{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from cleantext import clean\n",
    "import scipy\n",
    "import gensim\n",
    "from collections import defaultdict\n",
    "from nltk.stem import PorterStemmer  \n",
    "import mittens\n",
    "import tensorflow as tf\n",
    "import bert\n",
    "import genderdecoder\n",
    "from bert import optimization\n",
    "from bert import run_classifier\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "logger = tf.get_logger()\n",
    "logger.propagate = False\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bert import tokenization\n",
    "bert_model_hub = \"https://tfhub.dev/google/small_bert/bert_uncased_L-4_H-256_A-4/1\"\n",
    "max_seq_len = 128  # this is relatively small and helps keep the compute cost down\n",
    "label_list = ['masculine-coded', 'feminine-coded', 'neutral']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "corpus = pd.read_csv('DataAnalyst.csv')\n",
    "files = corpus[\"Job Description\"]\n",
    "\n",
    "def f(e):\n",
    "    cleaned = clean.clean(e,\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "    lower=True,                     # lowercase text\n",
    "    no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=True,                  # replace all URLs with a special token\n",
    "    no_emails=True,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "    no_numbers=True,               # replace all numbers with a special token\n",
    "    no_digits=True,                # replace all digits with a special token\n",
    "    no_currency_symbols=True,      # replace all currency symbols with a special token\n",
    "    no_punct=True,                 # remove punctuations\n",
    "    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "    replace_with_url=\"<URL>\",\n",
    "    replace_with_email=\"<EMAIL>\",\n",
    "    replace_with_phone_number=\"<PHONE>\",\n",
    "    replace_with_number=\"<NUMBER>\",\n",
    "    replace_with_digit=\"0\",\n",
    "    replace_with_currency_symbol=\"<CUR>\",\n",
    "    lang=\"en\"                       # set to 'de' for German special handling\n",
    "    )\n",
    "    return cleaned\n",
    "    \n",
    "words = files.map(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label dataset\n",
    "labeled_words = {}\n",
    "for word in words:\n",
    "    d = genderdecoder.assess(word)['result']\n",
    "    if  d == 'strongly masculine-coded':\n",
    "        d = 'masculine-coded'\n",
    "    elif d == 'strongly feminine-coded':\n",
    "        d = 'feminine-coded'\n",
    "    labeled_words[word] = d\n",
    "\n",
    "print(labeled_words.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write labeled dataset as dataframe\n",
    "all_text = list(labeled_words.keys())\n",
    "all_labels = list(labeled_words.values())\n",
    "labeled_data = pd.DataFrame(list(zip(all_text, all_labels)))\n",
    "labeled_data.columns = ['Job Description', 'Label']\n",
    "print(labeled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_text = labeled_data['Job Description']\n",
    "all_labels = labeled_data['Label']\n",
    "print(f\"Total dataset length is {len(all_text)} samples\")\n",
    "\n",
    "n_test = 40\n",
    "n_dev  = 200\n",
    "train_text, test_text, train_scores, test_scores = train_test_split(all_text, all_labels, test_size=n_test, shuffle=True)\n",
    "train_text, dev_text, train_scores, dev_scores = train_test_split(train_text, train_scores, test_size=n_dev, shuffle=True)\n",
    "print(f\"Train dataset has length {len(train_text)} samples\")\n",
    "print(f\"Dev dataset has length    {len(dev_text)} samples\")\n",
    "print(f\"Test dataset has length   {len(test_text)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataset splits to disk\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_split(text, scores, split_name):\n",
    "    data = {\"Text\": text, \"Score\": scores}\n",
    "    df = pd.concat(data, axis=1)\n",
    "    df.to_csv(f\"Jobposting_{split_name}.csv\")\n",
    "    return\n",
    "\n",
    "save_split(train_text, train_scores, \"train\")\n",
    "save_split(test_text, test_scores, \"test\")\n",
    "save_split(dev_text, dev_scores, \"dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(split_name):\n",
    "    df = pd.read_csv(f\"Jobposting_{split_name}.csv\")\n",
    "    text = df[\"Text\"]\n",
    "    scores = df[\"Score\"]\n",
    "    return text, scores\n",
    "\n",
    "train_text, train_scores = load_split(\"train\")\n",
    "test_text, test_scores = load_split(\"test\")\n",
    "dev_text, dev_scores = load_split(\"dev\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance the label classes for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_f = sum([s==\"feminine-coded\" for s in train_scores] )\n",
    "count_m = sum([s==\"masculine-coded\" for s in train_scores] )\n",
    "count_n = sum([s==\"neutral\" for s in train_scores] )\n",
    "print(count_f, count_m, count_n)\n",
    "balanced_train_text = []\n",
    "balanced_train_scores = []\n",
    "\n",
    "repeat_f = int(count_m / count_f)\n",
    "repeat_n = int(count_m/ count_n)\n",
    "#tracking numbers of samples in each set\n",
    "new_count_f = 0\n",
    "new_count_m = 0\n",
    "new_count_n = 0\n",
    "\n",
    "for t, s in zip(train_text, train_scores):\n",
    "    if s==\"feminine-coded\":\n",
    "        new_count_f += repeat_f\n",
    "        balanced_train_text += [t]*repeat_f\n",
    "        balanced_train_scores += [s]*repeat_f\n",
    "    if s==\"neutral\":\n",
    "        new_count_n += repeat_n\n",
    "        balanced_train_text += [t]*repeat_n\n",
    "        balanced_train_scores += [s]*repeat_n\n",
    "    if s==\"masculine-coded\":\n",
    "        new_count_m += 1\n",
    "        balanced_train_text += [t]\n",
    "        balanced_train_scores += [s]\n",
    "print(new_count_f, new_count_m, new_count_n)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the tokenizer\n",
    "with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(bert_model_hub)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "        vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"], tokenization_info[\"do_lower_case\"]])      \n",
    "    tokenizer = bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "    \n",
    "# Example of tokenization\n",
    "print(\"\\nEXAMPLE:\")\n",
    "print(tokenizer.tokenize(\"apply to this job with your unreasonable talents\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "def create_examples(text, scores):    \n",
    "    examples = []\n",
    "    for t, s in zip(text, scores):\n",
    "        t = t.replace(\"<br />\", \"\")   # custom data clean-up\n",
    "        tokens = tokenizer.tokenize(t)\n",
    "        \n",
    "        # If the entire text fits, then there is no need to\n",
    "        # use text b\n",
    "        if len(tokens) < 128:\n",
    "            text_a = t\n",
    "            text_b = None\n",
    "            \n",
    "        # If text is long, split into the first 64 and last 64 tokens\n",
    "        # only append complete sentences\\\n",
    "        else:\n",
    "            target_length = max_seq_len//2\n",
    "            text_a = \"\"\n",
    "            for sentence in nltk.tokenize.sent_tokenize(t):\n",
    "                if len(tokenizer.tokenize(text_a)) < target_length:\n",
    "                    text_a += sentence + \" \"\n",
    "                else:\n",
    "                    break\n",
    "            text_a = text_a.strip()  # remove trailing whitespace\n",
    "                \n",
    "            text_b = \"\"\n",
    "            for sentence in reversed(nltk.tokenize.sent_tokenize(t)):\n",
    "                if len(tokenizer.tokenize(sentence + \" \" + text_b)) <= target_length:\n",
    "                    text_b = sentence + \" \" + text_b\n",
    "                else:\n",
    "                    break\n",
    "            text_b = text_b.strip()  # remove trailing whitespace\n",
    "            text_a += \" \" + text_b\n",
    "            text_a = text_a.replace(\"  \", \" \")\n",
    "        \n",
    "        example = bert.run_classifier.InputExample(guid=None, text_a = text_a, text_b = None, label = s)\n",
    "        examples.append(example)\n",
    "    return examples\n",
    "train_examples = create_examples(train_text, train_scores)\n",
    "dev_examples = create_examples(dev_text, dev_scores)\n",
    "test_examples = create_examples(test_text, test_scores)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the split data sets to disk\n",
    "writer = bert.run_classifier.file_based_convert_examples_to_features\n",
    "writer(train_examples, label_list, max_seq_len, tokenizer, \"balanced_training\")\n",
    "writer(dev_examples, label_list, max_seq_len, tokenizer, \"dev\")\n",
    "writer(test_examples, label_list, max_seq_len, tokenizer, \"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
