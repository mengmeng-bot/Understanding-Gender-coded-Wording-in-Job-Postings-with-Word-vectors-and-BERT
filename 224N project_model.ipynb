{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "logger = tf.get_logger()\n",
    "logger.propagate = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_hub = \"https://tfhub.dev/google/small_bert/bert_uncased_L-4_H-512_A-8/1\"\n",
    "model_output_dir = \"finetuned_weights/bert_small\"\n",
    "tf.gfile.MakeDirs(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, num_labels):\n",
    "    bert_module = hub.Module(bert_model_hub, trainable=not is_predicting)\n",
    "    bert_inputs = dict(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(inputs=bert_inputs, signature=\"tokens\", as_dict=True)\n",
    "    \n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "    A = tf.get_variable(\"output_weights\", [hidden_size, num_labels], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    bias = tf.get_variable(\"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dropout(rate=0.1)(output_layer, training= not is_predicting)\n",
    "    logits = tf.nn.xw_plus_b(output_layer, A, bias)\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "        return predictions, logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
    "    def model_fn(features, labels, mode, params):\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "        # TRAIN and EVAL\n",
    "        if not is_predicting:\n",
    "            predictions, logits = create_model(is_predicting, input_ids, input_mask, segment_ids, num_labels)\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(label_ids, logits, from_logits=True)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "            train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "            \n",
    "             # Calculate evaluation metrics. \n",
    "            def metric_fn(label_ids, predictions):\n",
    "                accuracy = tf.metrics.accuracy(label_ids, predictions)\n",
    "                return {\"accuracy\": accuracy}\n",
    "            \n",
    "            eval_metrics = metric_fn(label_ids, predictions)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "            else:\n",
    "                # Calculate evaluation metrics. \n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
    "        else:\n",
    "            predictions, logits = create_model(is_predicting, input_ids, input_mask, segment_ids, num_labels)\n",
    "            probs = tf.nn.softmax(logits,axis=-1)\n",
    "            predictions = {'probabilities': probs, 'predictions': predictions,\n",
    "                           'labels' : label_ids, \"input_ids\": input_ids}\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "batch_size = 64\n",
    "max_seq_len = 128\n",
    "learning_rate = 5e-5\n",
    "num_train_steps = 20000//batch_size\n",
    "num_warmup_steps = 0\n",
    "num_labels = 3 # i.e. num_categories\n",
    "\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(model_dir=model_output_dir, save_summary_steps=10,\n",
    "                                    save_checkpoints_steps=500, keep_checkpoint_max=2)\n",
    "\n",
    "model_fn = model_fn_builder(num_labels, learning_rate=learning_rate, num_train_steps=num_train_steps,\n",
    "                            num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config,\n",
    "                                   params={\"batch_size\": batch_size})\n",
    "\n",
    "train_input_fn = bert.run_classifier.file_based_input_fn_builder(\"balanced_training\", max_seq_len,\n",
    "                                                                 is_training=True, drop_remainder=True)\n",
    "print(f\"Training for {num_train_steps} steps\")\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check metrics on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = bert.run_classifier.file_based_input_fn_builder(\"training\", max_seq_len,\n",
    "                                                           is_training=False,\n",
    "                                                           drop_remainder=False)\n",
    "estimator.evaluate(input_fn=input_fn, steps=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_input_fn = bert.run_classifier.file_based_input_fn_builder(\"dev\", max_seq_len, is_training=False, drop_remainder=False)\n",
    "estimator.evaluate(input_fn=dev_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_input_fn = bert.run_classifier.file_based_input_fn_builder(\"dev\", max_seq_len, is_training=False, drop_remainder=False)\n",
    "predictions = list(estimator.predict(input_fn=dev_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for e in predictions:\n",
    "    y_true.append(e[\"predictions\"])\n",
    "    y_pred.append(e[\"labels\"])\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"masculine coded\", \"feminine coded\", \"neutral\"])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
