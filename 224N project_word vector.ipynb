{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import cleantext\n",
    "import scipy\n",
    "import gensim\n",
    "from collections import defaultdict\n",
    "from nltk.stem import PorterStemmer \n",
    "import mittens\n",
    "import tensorflow as tf\n",
    "from tensorflow import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genderdecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('DataAnalyst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = corpus[\"Job Description\"]\n",
    "\n",
    "def f(e):\n",
    "    cleaned = cleantext.clean(e,\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "    lower=True,                     # lowercase text\n",
    "    no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=True,                  # replace all URLs with a special token\n",
    "    no_emails=True,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "    no_numbers=True,               # replace all numbers with a special token\n",
    "    no_digits=True,                # replace all digits with a special token\n",
    "    no_currency_symbols=True,      # replace all currency symbols with a special token\n",
    "    no_punct=True,                 # remove punctuations\n",
    "    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "    replace_with_url=\"<URL>\",\n",
    "    replace_with_email=\"<EMAIL>\",\n",
    "    replace_with_phone_number=\"<PHONE>\",\n",
    "    replace_with_number=\"<NUMBER>\",\n",
    "    replace_with_digit=\"0\",\n",
    "    replace_with_currency_symbol=\"<CUR>\",\n",
    "    lang=\"en\"                       # set to 'de' for German special handling\n",
    "    )\n",
    "    return cleaned\n",
    "    \n",
    "words = files.map(f)   \n",
    "#files.map(str.split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderdecoder.assess(words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas_stats = 0\n",
    "s_mas_stats = 0\n",
    "s_fem_stats = 0\n",
    "fem_stats = 0\n",
    "neu_stats = 0\n",
    "for word in words:\n",
    "    score = genderdecoder.assess(word)['result']\n",
    "    if score == 'masculine-coded':\n",
    "        mas_stats += 1\n",
    "    elif score == 'strongly masculine-coded':\n",
    "        s_mas_stats += 1\n",
    "    elif score == 'feminine-coded':\n",
    "        fem_stats += 1\n",
    "    elif score == 'strongly feminine-coded':\n",
    "        s_fem_stats += 1\n",
    "        \n",
    "    elif score == 'neutral':\n",
    "        neu_stats += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mas_stats, s_mas_stats, fem_stats, s_fem_stats, neu_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pie chart\n",
    "labels = 'masculine-coded','strongly masculine-coded', 'feminine-coded','strongly feminine-coded','neutral'\n",
    "sizes = [1509, 178, 381, 24, 161]\n",
    "explode = (0.1, 0, 0, 0, 0)\n",
    "\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove vector, sort based on cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine similarity between two words\n",
    "def cosine_sim(v1, v2):\n",
    "    return scipy.spatial.distance.cosine(v1, v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing glove vectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "wv_from_bin = api.load(\"glove-wiki-gigaword-200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(wv_from_bin.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas_list = genderdecoder.masculine_coded_words\n",
    "fem_list = genderdecoder.feminine_coded_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute cosine_sim between all the glove vectors and mas/fem_list words\n",
    "#order the words based on their similarity to either feminine/masculine words\n",
    "femwords = fem_list\n",
    "fem_results = {k: 0 for k in wv_from_bin.vocab}\n",
    "for femword in femwords:\n",
    "    for vocab_word in wv_from_bin.vocab:\n",
    "        if vocab_word.startswith(femword):\n",
    "            top_5 = wv_from_bin.similar_by_word(vocab_word, 10)\n",
    "            for word, score in top_5:\n",
    "                if not any([word.startswith(f) for f in femwords]): # don't update the words that starts with femwords\n",
    "                    # Average score\n",
    "                    \n",
    "                    fem_results[word] += score\n",
    "\n",
    "# Order by total similarity\n",
    "total_similarity = sorted(fem_results.items(), key=lambda x: -x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most similar words\n",
    "total_similarity[:50]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_new = defaultdict(int)\n",
    "for word, score in fem_results.items():\n",
    "    word_stem = stemmer.stem(word)\n",
    "    stemmed_new[word_stem] += score\n",
    "total_similarity_per_stem = sorted(stemmed_new.items(), key=lambda x: -x[1])\n",
    "total_similarity_per_stem[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maswords = mas_list\n",
    "mas_results = {k: 0 for k in wv_from_bin.vocab}\n",
    "for masword in maswords:\n",
    "    for vocab_word in wv_from_bin.vocab:\n",
    "        if vocab_word.startswith(masword):\n",
    "            top_5 = wv_from_bin.similar_by_word(vocab_word, 10)\n",
    "            for word, score in top_5:\n",
    "                if not any([word.startswith(m) for m in maswords]): # don't update the words that starts with femwords\n",
    "                    # Average score\n",
    "                    \n",
    "                    mas_results[word] += score\n",
    "\n",
    "# Order by total similarity\n",
    "total_similarity = sorted(mas_results.items(), key=lambda x: -x[1])\n",
    "total_similarity[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_new = defaultdict(int)\n",
    "for word, score in mas_results.items():\n",
    "    word_stem = stemmer.stem(word)\n",
    "    stemmed_new[word_stem] += score\n",
    "total_similarity_per_stem = sorted(stemmed_new.items(), key=lambda x: -x[1])\n",
    "total_similarity_per_stem[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Train Glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_words(words):\n",
    "    \n",
    "    corpus_words = []\n",
    "    num_corpus_words = -1\n",
    "    \n",
    "    corpus_words = sorted(set([word for lst in corpus for word in lst]))\n",
    "    num_corpus_words = len(corpus_words)\n",
    "\n",
    "    return corpus_words, num_corpus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_co_occurrence_matrix(corpus, window_size=4):\n",
    "   \n",
    "    words_words, num_words = distinct_words(words)\n",
    "    M = None\n",
    "    word2ind = {}\n",
    "        \n",
    "    for i, word in enumerate(words_words):\n",
    "        word2ind[word] = i\n",
    "        \n",
    "    M = np.zeros((num_words, num_words))\n",
    "    for sentence in corpus:\n",
    "        for i, word in enumerate(sentence):\n",
    "            for j in range(max(i-window_size, 0), min(i+window_size, len(sentence))):\n",
    "                # check i != j\n",
    "                if i != j:\n",
    "                    M[word2ind[word], word2ind[sentence[j]]] += 1\n",
    "                    M[word2ind[sentence[j]], word2ind[word]] += 1\n",
    "\n",
    "   \n",
    "            \n",
    "    return M, word2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_words = wv_from_bin.vocab\n",
    "corpus = [list(filter(lambda w: w in allowed_words, sentence.split())) for sentence in words]\n",
    "M, word2ind = compute_co_occurrence_matrix(corpus, window_size = 4)\n",
    "print(word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mittens import GloVe\n",
    "glove_model = GloVe(n=32, max_iter=100)\n",
    "embeddings = glove_model.fit(M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gender-coded-glove.txt\", \"w\") as f:\n",
    "    for i, embed_word in enumerate(word2ind.keys()):\n",
    "        print(embed_word, \" \".join(map(str, embeddings[i])), file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'gender-coded-glove.txt'\n",
    "word2vec_output_file = 'gender-coded-w2v.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wv_from_dataset = model = KeyedVectors.load_word2vec_format('gender-coded-w2v.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "femwords = fem_list\n",
    "fem_results = {k: 0 for k in wv_from_dataset.vocab}\n",
    "for femword in femwords:\n",
    "    for vocab_word in wv_from_dataset.vocab:\n",
    "        if vocab_word.startswith(femword):\n",
    "            top_5 = wv_from_dataset.similar_by_word(vocab_word, 10)\n",
    "            for word, score in top_5:\n",
    "                if not any([word.startswith(f) for f in femwords]): # don't update the words that starts with femwords\n",
    "                    # Average score\n",
    "                    fem_results[word] += score\n",
    "                    \n",
    "# Order by total similarity\n",
    "total_similarity = sorted(fem_results.items(), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_new = defaultdict(int)\n",
    "for word, (score, count) in fem_results.items():\n",
    "    word_stem = stemmer.stem(word)\n",
    "    stemmed_new[word_stem] += score\n",
    "total_similarity_per_stem = sorted(stemmed_new.items(), key=lambda x: -x[1])\n",
    "total_similarity_per_stem[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maswords = mas_list\n",
    "mas_results = {k: 0 for k in wv_from_dataset.vocab}\n",
    "for masword in maswords:\n",
    "    for vocab_word in wv_from_dataset.vocab:\n",
    "        if vocab_word.startswith(masword):\n",
    "            top_5 = wv_from_dataset.similar_by_word(vocab_word, 10)\n",
    "            for word, score in top_5:\n",
    "                if not any([word.startswith(f) for f in maswords]): # don't update the words that starts with femwords\n",
    "                    # Average score\n",
    "                    \n",
    "                    mas_results[word] += score\n",
    "\n",
    "# Order by total similarity\n",
    "total_similarity = sorted(mas_results.items(), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_similarity[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_new = defaultdict(int)\n",
    "for word, (score, count) in mas_results.items():\n",
    "    word_stem = stemmer.stem(word)\n",
    "    stemmed_new[word_stem] += score\n",
    "total_similarity_per_stem = sorted(stemmed_new.items(), key=lambda x: -x[1])\n",
    "total_similarity_per_stem[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
